> [0. Acerca del Grupo](../../0.md) ‚Ä∫ [0.6. Temas Individuales (Parte 1)](../0.6.md) ‚Ä∫ [0.6.4. Integrante 4](0.6.4.md)

# 0.6.4. Ana Meza
---
# üß† Desarrollo Conceptual ‚Äî Orquestaci√≥n de Contenedores

## ‚úÖ ¬øQu√© es?
La **orquestaci√≥n de contenedores** es el conjunto de pr√°cticas y componentes que automatizan el **despliegue, escalado, actualizaci√≥n y operaci√≥n** de aplicaciones en contenedores sobre un **cl√∫ster**. Funciona de forma **declarativa**: defines el *estado deseado* (p. ej., ‚Äú3 r√©plicas de este servicio‚Äù) y el orquestador lo mantiene mediante **reconciliaci√≥n**, gestionando redes, almacenamiento, secretos, pol√≠ticas y observabilidad.

### üñáÔ∏è ¬øQu√© es un cl√∫ster?
Un **cl√∫ster** es un **conjunto de m√°quinas** (f√≠sicas o virtuales) que operan como un sistema √∫nico:
- **Plano de control**: decide y coordina (API, scheduler, controladores).
- **Nodos de trabajo** (*workers*): ejecutan los contenedores/pods.
- Comparten **red** y, cuando aplica, **almacenamiento**, habilitando **alta disponibilidad** y **escalado** al distribuir la carga y reemplazar instancias con fallas autom√°ticamente.

---

## üåü ¬øPor qu√© usar un orquestador?
- **Alta disponibilidad y autorreparaci√≥n** (recrea pods si fallan).
- **Escalabilidad horizontal autom√°tica** (HPA/VPA) seg√∫n carga o m√©tricas.
- **Despliegues seguros y sin ca√≠da**: *rolling*, *blue/green*, *canary* y **rollback**.
- **Estandarizaci√≥n operativa** (red, vol√∫menes, secretos, pol√≠ticas).
- **Uso eficiente de recursos** (bin-packing con *requests/limits*).
- **Observabilidad** integrada (m√©tricas, logs, trazas) para SRE.

---

## üü© Cu√°ndo conviene
- **Microservicios** o m√∫ltiples servicios que deben alinearse.
- **Picos de demanda** y necesidad de **autoscaling**.
- **Entornos multi-equipo** con cuotas, aislamiento y pol√≠ticas.
- **Entrega continua** con despliegues frecuentes y *rollback* √°gil.
- **Plataformas internas** (PaaS) que hospedan varios productos.

## üü• Cu√°ndo *no* conviene
- Proyectos **peque√±os/est√°ticos** (un servicio simple sin escalar).
- Equipos **sin capacidad operativa** para administrar un cl√∫ster.
- Workloads con **dependencias muy host-acopladas**.
- Requisitos de **tiempo real duro** donde la sobrecarga no es aceptable.

---

## ‚ö†Ô∏è Desaf√≠os y riesgos (a gestionar)
- **Curva de aprendizaje** y complejidad operativa.
- **Costos** por sobredimensionamiento o *requests/limits* mal definidos.
- **Seguridad**: exfiltraci√≥n de secretos, im√°genes vulnerables, red abierta.
- **Observabilidad** insuficiente complica diagn√≥stico y *MTTR*.

---

## üß© Componentes y conceptos clave (agn√≥sticos)
| Capa | Qu√© hace | Ejemplos |
|---|---|---|
| **Plano de control** | Mantiene estado deseado y programa cargas | API Server, Scheduler, Controladores |
| **Plano de datos** | Ejecuta contenedores y expone red/vol√∫menes | Nodos de trabajo + runtime |
| **Red (CNI)** | Conectividad y pol√≠ticas L3/L4 | Calico, Cilium, Flannel |
| **Almacenamiento (CSI)** | Provisi√≥n de vol√∫menes y *claims* | HostPath, NFS, Ceph |
| **Identidad y acceso** | Permisos por rol | RBAC, ServiceAccounts |
| **Observabilidad** | M√©tricas, logs, trazas | metrics-server, Prometheus/Grafana, Loki/ELK, OpenTelemetry |

---

## üõ†Ô∏è Objetos/patrones t√≠picos
| Objeto/Patr√≥n | Qu√© resuelve | Ejemplo |
|---|---|---|
| **Deployment** | R√©plicas y estrategia de actualizaci√≥n | 3 pods con *rolling update* 25%/25% |
| **Service** | Descubrimiento y balanceo L4 | `ClusterIP` (interno), `NodePort/LoadBalancer` (externo) |
| **Ingress / Gateway** | Enrutamiento HTTP/HTTPS L7 | Ruta `/api` ‚Üí servicio `backend` con TLS |
| **ConfigMap / Secret** | Config y credenciales fuera del c√≥digo | `APP_MODE=prod`, token base64 |
| **Job / CronJob** | Tareas puntuales o programadas | ETL diario 03:00 |
| **HPA / VPA** | Autoscaling por m√©tricas o ajuste de recursos | Escalar si CPU > 70% |
| **NetworkPolicy** | Control de tr√°fico entre pods | Solo `frontend` ‚Üí `api` |

---

## üîÅ Estrategias de despliegue
| Estrategia | √ösala cuando‚Ä¶ | Trade-off |
|---|---|---|
| **Rolling Update** | Cambios frecuentes con bajo riesgo | M√≠nimo riesgo; propagaci√≥n gradual |
| **Recreate** | Incompatibilidad de estado/sesiones | Downtime breve |
| **Blue/Green** | Cambios grandes; *rollback* instant√°neo | Requiere doble capacidad |
| **Canary** | Validar con % peque√±o de tr√°fico | Mayor complejidad de ruteo/telemetr√≠a |

---

## üìè M√©tricas clave de operaci√≥n
- **Disponibilidad (SLA/SLO)** y **error rate** por servicio.  
- **Latencias** P50/P95/P99 en endpoints cr√≠ticos.  
- **CPU/RAM** usados vs *requests/limits* (evitar *throttling* y **OOMKilled**).  
- **Tiempo de despliegue** y **tasa de rollback**.  
- **MTTR** ante fallas y **saturaci√≥n** (colas, conexiones, l√≠mites de pod/nodo).

---

## üìö Glosario r√°pido
- **Pod**: unidad m√≠nima de ejecuci√≥n (uno o m√°s contenedores).  
- **ReplicaSet**: mantiene el n√∫mero de pods.  
- **Namespace**: segmentaci√≥n l√≥gica de recursos.  
- **CNI/CSI**: interfaces de red/almacenamiento para plugins.  
- **GitOps**: manifiestos en Git como **fuente de verdad** y reconciliaci√≥n continua.

> **Nota:** Este marco es **independiente del proveedor** (Kubernetes, Nomad, Swarm). La demo del repositorio se ejecutar√° en un **cl√∫ster local** con manifiestos YAML est√°ndar.

## **DEMO**
> **Objetivo:** Desplegar una app HTTP simple en Kubernetes local, exponerla, escalarla, hacer un rolling update y demostrar autorreparaci√≥n.  
> **Entorno usado:** Windows + Docker Desktop + `kubectl` + `kind` v1.30.0

---

## 0) Requisitos previos

- Docker Desktop/Engine activo  
- `kubectl` instalado  
- `kind` instalado  
- 2 vCPU y 4 GB RAM libres

Verificaci√≥n r√°pida:
```powershell
docker --version
kubectl version --client
kind --version
```
## 1) Crear el cl√∫ster local
```powershell
kind create cluster --name demo-orq --image kindest/node:v1.30.0
kubectl cluster-info --context kind-demo-orq
kubectl get nodes
```
## 2) Preparar la imagen en el cl√∫ster (evitar ImagePullBackOff)
```powershell
docker pull hashicorp/http-echo:0.2.3
kind load docker-image hashicorp/http-echo:0.2.3 --name demo-orq
```
## 3) Crear manifiesto YAML (namespace, deployment y service)
```powershell
mkdir k8s -Force
notepad .\k8s\demo.yaml
```

Pegas esto: 
```powershell
apiVersion: v1
kind: Namespace
metadata:
  name: demo
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-api
  namespace: demo
spec:
  replicas: 3
  selector:
    matchLabels:
      app: hello-api
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  template:
    metadata:
      labels:
        app: hello-api
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 10001
      containers:
        - name: app
          image: hashicorp/http-echo:0.2.3
          imagePullPolicy: IfNotPresent
          args: ["-text=Hola desde Kubernetes üëã", "-listen=:8080"]
          ports:
            - containerPort: 8080
          resources:
            requests: { cpu: "50m", memory: "64Mi" }
            limits:   { cpu: "200m", memory: "128Mi" }
          livenessProbe:
            httpGet: { path: "/", port: 8080 }
            initialDelaySeconds: 5
            periodSeconds: 10
          readinessProbe:
            httpGet: { path: "/", port: 8080 }
            initialDelaySeconds: 2
            periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: hello-svc
  namespace: demo
spec:
  type: NodePort
  selector:
    app: hello-api
  ports:
    - name: http
      port: 80
      targetPort: 8080
      nodePort: 30080
```
Aplicar y verificar:
```powershell
kubectl apply -f .\k8s\demo.yaml
kubectl -n demo get deploy,rs,pods,svc -o wide
```
## 4) Acceder al servicio (port-forward)
En Windows + kind, el NodePort puede no abrirse en localhost(a mi me salio ese error unu). Para la demo usamos port-forward:
```powershell
kubectl -n demo port-forward svc/hello-svc 18180:80
```
Deja esa consola abierta. En otra consola o navegador:
```powershell
curl.exe http://127.0.0.1:18180/
```
## 5) Escalado sin ca√≠da
```powershell
kubectl -n demo scale deploy/hello-api --replicas=5
kubectl -n demo get deploy,rs,pods -o wide
```
![alt text](image.png)

## 6) Rolling update (cambio visible) y rollback
Edita el Deployment para actualizar el mensaje:
```powershell
kubectl -n demo edit deploy/hello-api
```
Cambia el bloque args a:
```powershell
args:
  - "-text=Hola desde K8s v2 üöÄ"
  - "-listen=:8080"
```
Guarda y espera el rollout:
```powershell
kubectl -n demo rollout status deploy/hello-api
```
Refresca la URL http://127.0.0.1:18180/ ‚Äî ver√°s el nuevo texto.
![alt text](image-1.png)

## 7) Autorreparaci√≥n (self-healing)
```powershell
kubectl -n demo delete pod -l app=hello-api --force --grace-period=0
kubectl -n demo get pods -w
```
## 8) Comprobaciones y evidencias
```powershell
kubectl get nodes
kubectl -n demo get deploy,rs,pods,svc -o wide
kubectl -n demo describe deploy/hello-api
kubectl -n demo logs -l app=hello-api --tail=50
```

## Resumen final de lo realizado
- Despliegue declarativo (Deployment + Service)

- Descubrimiento y exposici√≥n del servicio

- Escalado horizontal sin ca√≠da

- Rolling update (y rollback)

Autorreparaci√≥n autom√°tica
[‚¨ÖÔ∏è Anterior](../0.6.3/0.6.3.md) | [üè† Home](../../../README.md) | [Siguiente ‚û°Ô∏è](../0.6.5/0.6.5.md)